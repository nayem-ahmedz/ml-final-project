# -*- coding: utf-8 -*-
"""ML Final Project using Online Shoppers Purchasing Intention Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1thLPsEKGqMePonOFGQ77ar-zu79azpXT

### **Machine Learning Final Project**

By
1.   Nayem Ahmed (221-115-003)
2.   Hajifa Begum Jui (221-115-013)
3.   Rabeya Akter (221-115-010)

**Task 1: Exploratory Data Analysis (EDA)**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plot
import seaborn as sns

# dataset link : https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset

df = pd.read_csv('/content/online_shoppers_intention.csv')
df.describe()
df.head()

# Scatter Plot

plot.figure(figsize=(8, 6))
sns.scatterplot(x='ProductRelated_Duration', y='PageValues', data=df, hue='Revenue')
plot.title('Scatter Plot: ProductRelated_Duration vs PageValues')
plot.show()

df.hist(bins=20, figsize=(15, 10))
plot.suptitle('Histograms for Numerical Features')
plot.show()

# Bar Chart
df['Browser'].value_counts().plot(kind='bar', figsize=(8, 6))
plot.title('Browser Usage Distribution')
plot.xlabel('Browser')
plot.ylabel('Count')
plot.show()

# Pie Chart
df['Revenue'].value_counts().plot(kind='pie', autopct='%1.1f%%', labels=['No Revenue', 'Revenue'], figsize=(6, 6))
plot.title('Revenue Proportion')
plot.ylabel('')
plot.show()

# Heatmap

# Selecting numeric columns
numeric_df = df.select_dtypes(include=['number'])

correlation_matrix = numeric_df.corr()

sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')
plot.title('Correlation Heatmap')
plot.show()

"""**Task 2: Data Preprocessing**"""

# Handling Null Values

print('Null values before cleaning:')
print(df.isnull().sum())

df.fillna(method='bfill', inplace=True)
print('Null values after cleaning:')
print(df.isnull().sum())

# Boxplot for Outliers
for column in ['Administrative_Duration', 'Informational_Duration', 'ProductRelated_Duration']:
    sns.boxplot(x=df[column])
    plot.title(f'Boxplot for {column}')
    plot.show()

# Scaling using MinMax Scaler

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaled_features = scaler.fit_transform(df[['Administrative_Duration', 'Informational_Duration', 'ProductRelated_Duration']])
df[['Administrative_Duration', 'Informational_Duration', 'ProductRelated_Duration']] = scaled_features

# Check Class Imbalance

df['Revenue'].value_counts().plot(kind='bar', color=['blue', 'orange'])
plot.title('Class Balance for Revenue')
plot.xlabel('Revenue')
plot.ylabel('Count')
plot.show()

# converting categorical values

df = pd.get_dummies(df, columns=['Month', 'VisitorType'], drop_first=True)
df['Weekend'] = df['Weekend'].astype(int)
df['Revenue'] = df['Revenue'].astype(int)

"""**Split dataset into train and test set**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder

# Scaling numerical columns
scaler = MinMaxScaler()
numerical_features = df.select_dtypes(include=['float64', 'int64']).columns.drop('Revenue')
df[numerical_features] = scaler.fit_transform(df[numerical_features])

# Splitting data
X = df.drop('Revenue', axis=1)
y = df['Revenue']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**Task 3: Fit to ML Model**"""

# Random Forest

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Evaluate
y_pred_rf = rf_model.predict(X_test)
print("Random Forest Results:")
print(classification_report(y_test, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))

# Sklearn MLPClassifier

from sklearn.neural_network import MLPClassifier

mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)
mlp_model.fit(X_train, y_train)

y_pred_nn = mlp_model.predict(X_test)
print("MLP Neural Network Results:")
print(classification_report(y_test, y_pred_nn))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_nn))

# TensorFlow

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical
y_train_ann = to_categorical(y_train)
y_test_ann = to_categorical(y_test)

ann_model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(2, activation='softmax')  # Output layer for binary classification
])

# Compile the model
ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
ann_model.fit(X_train, y_train_ann, epochs=20, batch_size=32, validation_split=0.2, verbose=1)

# Evaluate
loss, accuracy = ann_model.evaluate(X_test, y_test_ann)
print(f"ANN Accuracy: {accuracy * 100:.2f}%")

# DNN (Deep Nueral Network)

# Build the DNN Model
dnn_model = Sequential([
    Dense(128, input_dim=X_train.shape[1], activation='relu'),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(2, activation='softmax')  # Output layer for binary classification
])

# Compile the model
dnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
dnn_model.fit(X_train, y_train_ann, epochs=30, batch_size=64, validation_split=0.2, verbose=1)

# Evaluate
loss, accuracy = dnn_model.evaluate(X_test, y_test_ann)
print(f"DNN Accuracy: {accuracy * 100:.2f}%")

"""**Task 4. Evaluation**

1. Metrics for Random Forest and MLPClassifier
"""

# Random Forest Evaluation
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score

# Confusion Matrix
cm_rf = confusion_matrix(y_test, y_pred_rf)
print("Confusion Matrix (Random Forest):\n", cm_rf)

# Classification Report
print("Classification Report (Random Forest):\n", classification_report(y_test, y_pred_rf))

# AUC-ROC for Random Forest
y_pred_rf_prob = rf_model.predict_proba(X_test)[:, 1]
roc_auc_rf = roc_auc_score(y_test, y_pred_rf_prob)
print(f"ROC-AUC Score (Random Forest): {roc_auc_rf:.2f}")

# Plot ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_rf_prob)
plot.plot(fpr, tpr, label=f"Random Forest (AUC = {roc_auc_rf:.2f})")
plot.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing
plot.title("ROC Curve")
plot.xlabel("False Positive Rate")
plot.ylabel("True Positive Rate")
plot.legend()
plot.show()

# Repeat similar evaluation for MLPClassifier
y_pred_nn_prob = mlp_model.predict_proba(X_test)[:, 1]
roc_auc_nn = roc_auc_score(y_test, y_pred_nn_prob)
print(f"ROC-AUC Score (MLPClassifier): {roc_auc_nn:.2f}")

"""2. Metrics for ANN/DNN"""

# Convert predictions to binary labels
y_pred_ann = ann_model.predict(X_test).argmax(axis=1)
y_pred_dnn = dnn_model.predict(X_test).argmax(axis=1)

# ANN Evaluation
print("Classification Report (ANN):\n", classification_report(y_test, y_pred_ann))
print("Confusion Matrix (ANN):\n", confusion_matrix(y_test, y_pred_ann))

# DNN Evaluation
print("Classification Report (DNN):\n", classification_report(y_test, y_pred_dnn))
print("Confusion Matrix (DNN):\n", confusion_matrix(y_test, y_pred_dnn))

# ANN AUC-ROC
y_pred_ann_prob = ann_model.predict(X_test)[:, 1]
roc_auc_ann = roc_auc_score(y_test, y_pred_ann_prob)
print(f"ROC-AUC Score (ANN): {roc_auc_ann:.2f}")

# DNN AUC-ROC
y_pred_dnn_prob = dnn_model.predict(X_test)[:, 1]
roc_auc_dnn = roc_auc_score(y_test, y_pred_dnn_prob)
print(f"ROC-AUC Score (DNN): {roc_auc_dnn:.2f}")

"""**Note:** My dataset does not include a regression target (continuous variable), so metrics like MSE, MAE, RMSE, and RÂ² are irrelevant here."""